{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97dd8c6",
   "metadata": {},
   "source": [
    "# Concordancer for the authors documented by identifier\n",
    "\n",
    "Script written by Morgane Pica for a submission to the symposium [\"Lire les classiques en Normandie\"](https://rmblf.be/2022/02/04/appel-a-contribution-lire-les-classiques-en-normandie/) (oct 2022), to be written by herself and Mathieu Goux.\n",
    "\n",
    "This script contains several functions, in this exact order in the file:\n",
    "* `get_w_text(word)` -> Function taking a `<tei:w>` element and returning its compiled textual content.\n",
    "* `title_str(div, div_type, div_count)` -> Function taking a `<tei:div>` element with lemmatized text and returning its title, if any.\n",
    "* `p_tokens(paragraph)` -> Function taking a `<tei:p>` element and returning all its words as a dictionary.\n",
    "* `dict_to_str(token_dict)` -> Function taking a dictionary as produced by `p_tokens()` and returning the corresponding string.\n",
    "* `get_context(paragraph, ref_numbers)` -> Function taking a dictionary as produced by `p_tokens()` and the list of the numbers of the tokens of a particular `<tei:ref>` element inside that paragraph, and sorting the tokens between left context, relevant text and right context.\n",
    "* `concordances(author_id, book_path)` -> Function taking the identifier of an author and the path to a TEI-XML file, and using the previous functions to gather relevant information on all mentions of this author in this file. It returns a dictionary for this author.\n",
    "    \n",
    "\n",
    "**À FAIRE** :\n",
    "* Renuméroter les tokens pour que tous aient un numéro.\n",
    "\n",
    "## Imports & declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401e3de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm #tqdm est bibliothèque qui permet d'avoir une barre de progression\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "ET.register_namespace(\"\", \"http://www.tei-c.org/ns/1.0\")\n",
    "ET.register_namespace('xml','http://www.w3.org/XML/1998/namespace')\n",
    "\n",
    "# Get current time\n",
    "dt = datetime.now()\n",
    "tmsp = dt.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Not all witnesses were enriched with reference identification.\n",
    "# Change paths to fit your own folder organization.\n",
    "witnesses = [\"basnage\",\"berault\",\"merville\",\"pesnelle\",\"terrien\"]\n",
    "binpath = \"/home/mpica/Progs/perso/CONDE/editions/base-version/\"\n",
    "einpath = \"_base.xml\"\n",
    "\n",
    "# Get Json documenting interesting authors.\n",
    "with open(\"authors.json\") as jsonf:\n",
    "    authors = json.load(jsonf)\n",
    "\n",
    "# Construct the path for outputs. \n",
    "current_dir = os.getcwd()\n",
    "new_dir = f\"{current_dir}/output/{tmsp}\"\n",
    "os.mkdir(new_dir)\n",
    "\n",
    "# Make CSV path now.\n",
    "csvpath = f'{new_dir}/occurrences.csv'\n",
    "\n",
    "# Change output paths here if you like.\n",
    "listfile = f\"{new_dir}/authors.csv\"\n",
    "tablefile = f\"{new_dir}/mentions.csv\"\n",
    "authortable = f\"{new_dir}/authors.csv\"\n",
    "authorjson = f\"{new_dir}/authors.json\"\n",
    "checklist = f\"{new_dir}/checklist.xml\"\n",
    "\n",
    "# Lists of characters to be treated particularly.\n",
    "noLspace = \",.)/]-'\"\n",
    "noRspace = \"(/[]-'\"\n",
    "# insecable = \";:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fdf5d1",
   "metadata": {},
   "source": [
    "## FUNCTION: extract text from tei:w element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d76607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_text(word):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function taking a <tei:w> element and\n",
    "    returning its compiled textual content.\n",
    "    \n",
    "    :param word: ET.Element('{http://www.tei-c.org/ns/1.0}w')\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparing the return string as an empty string.\n",
    "    texte = \"\"\n",
    "    \n",
    "    # If there is text directly inside <w> element and\n",
    "    # before the first child, add it.\n",
    "    if word.text:\n",
    "        texte += str(word.text)\n",
    "                \n",
    "    # Loop on all current <w> children.\n",
    "    for item in word:\n",
    "            \n",
    "        # If current child is <tei:height> or <tei:supplied>\n",
    "        if item.tag == '{http://www.tei-c.org/ns/1.0}height' or item.tag == '{http://www.tei-c.org/ns/1.0}supplied':\n",
    "            # Add text.\n",
    "            texte += str(item.text)\n",
    "            # If any, add the text following current child.\n",
    "            if item.tail:\n",
    "                texte += str(item.tail)\n",
    "                \n",
    "        # If current child is <tei:lb>, add the following text.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}lb':\n",
    "            if item.tail:\n",
    "                texte += str(item.tail)\n",
    "                        \n",
    "        # If current child is <tei:choice>, add the second child of <choice>\n",
    "        # (<tei:reg> or <tei:expan>), then add the text following current child if any.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}choice':\n",
    "            texte += str(item[1].text)\n",
    "            if item.tail:\n",
    "                texte += str(item.tail)\n",
    "        \n",
    "        # If current child is <tei:c>, add its text, then the following text if any.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}c':\n",
    "            texte += item.text\n",
    "            if item.tail:\n",
    "                texte += str(item.tail)\n",
    "        \n",
    "        \n",
    "        # If current child is <tei:hi>, add its text, then the following text if any.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}hi':\n",
    "            texte += item.text\n",
    "            if item.tail:\n",
    "                texte += item.tail\n",
    "        \n",
    "        # If current child is <tei:add>, loop on its children and do the same checks.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}add':\n",
    "            # On refait tous les tests.\n",
    "            if item.find('.') == None :\n",
    "                texte = str(item.text)\n",
    "                            \n",
    "            else:\n",
    "                        \n",
    "                if item.text:\n",
    "                    texte += str(item.text)\n",
    "                        \n",
    "                for subitem in item:\n",
    "                    if subitem.tag == '{http://www.tei-c.org/ns/1.0}lb':\n",
    "                        if subitem.tail:\n",
    "                            texte += str(subitem.tail)\n",
    "                    elif subitem.tag == '{http://www.tei-c.org/ns/1.0}choice':\n",
    "                        texte += str(subitem[1].text)\n",
    "                        if subitem.tail:\n",
    "                            texte += str(subitem.tail)\n",
    "                            \n",
    "    return texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb891c",
   "metadata": {},
   "source": [
    "## FUNCTION: Make title string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2976b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_str(div, dtype, dcount):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function taking a <tei:div> element with lemmatized text\n",
    "    and returning its title, if any.\n",
    "    \n",
    "    :param div: ET.Element('{http://www.tei-c.org/ns/1.0}div')\n",
    "    :param dtype: div.get('type') as string\n",
    "    :param dcount: integer\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Lists of characters to be treated particularly.\n",
    "    noLspace = \",.)/]-'\"\n",
    "    noRspace = \"(/[]-'\"\n",
    "    # insecable = \";:\"\n",
    "    \n",
    "    # List of strings to be filled.\n",
    "    divlist = []\n",
    "    \n",
    "    try:\n",
    "        # If you do find a title as first child of div, make its text.\n",
    "        if div.find('./*[1]').tag == \"{http://www.tei-c.org/ns/1.0}head\":\n",
    "            \n",
    "            # Loop on each <tei:w> word token.\n",
    "            for word in div.findall('./{http://www.tei-c.org/ns/1.0}head/{http://www.tei-c.org/ns/1.0}w'):\n",
    "                \n",
    "                # Compile the text of current <tei:w> element.\n",
    "                wtxt = get_w_text(word)\n",
    "                \n",
    "                # If the list is empty, add the current word to the list.\n",
    "                if len(divlist) == 0:\n",
    "                    divlist.append(wtxt)\n",
    "\n",
    "                # If the token is a punctuation character which\n",
    "                # is not separated from the previous word by a space,\n",
    "                # add it to the last entry in the list.\n",
    "                elif wtxt in noLspace:\n",
    "                    divlist[-1] += wtxt\n",
    "                \n",
    "                # If the last entry in the list is a character which\n",
    "                # is not separated from the next word by a space,\n",
    "                # add the current token to it.\n",
    "                elif divlist[-1] in noRspace:\n",
    "                    divlist[-1] += wtxt\n",
    "\n",
    "                # If the last letter in the last entry in the list is\n",
    "                # a character which is not separated from the next word\n",
    "                # by a space, add the current token to it.\n",
    "                elif divlist[-1][-1] in noRspace:\n",
    "                    divlist[-1] += wtxt\n",
    "\n",
    "                #elif wtxt in insecable:\n",
    "                #    divlist[-1] += \"\\u00a0\"\n",
    "                #    divlist[-1] += wtxt\n",
    "                \n",
    "                # Otherwise, just add the token as a new list entry.\n",
    "                else:\n",
    "                    divlist.append(wtxt)\n",
    "            \n",
    "            # Once you have treated every token in the title, make the\n",
    "            # return string by adding a space between each list entry.\n",
    "            title = \" \".join(divlist)\n",
    "        \n",
    "        # If there is no title to the div but it has an @subtype,\n",
    "        # its value makes the return string.\n",
    "        elif div.get('subtype') != None:\n",
    "            title = div.get('subtype')\n",
    "        \n",
    "        else:\n",
    "            title = \"Aucun titre.\"\n",
    "    \n",
    "    # Just a marker to spot errors within final output.\n",
    "    except Exception as e:\n",
    "        print(e, \"-> Could not construct string for: \"+ ET.tostring(word).decode('utf-8') + \" in \" + div.get('{http://www.w3.org/XML/1998/namespace}id'))\n",
    "        title = \"Pas réussi.\"\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39605295",
   "metadata": {},
   "source": [
    "## FUNCTION: Make a dictionary from the tokens in a paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0068c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_tokens(parag):\n",
    "    \n",
    "    pdict = {}\n",
    "    count = 0\n",
    "    \n",
    "    for child in parag.findall(\"./*\"):\n",
    "        \n",
    "        if child.tag == \"{http://www.tei-c.org/ns/1.0}w\":\n",
    "            count += 1\n",
    "            nb = child.get('n')\n",
    "            texte = get_w_text(child)\n",
    "            pdict[count] = {'nb':nb, 'text':texte}\n",
    "            \n",
    "            \n",
    "        elif child.tag == \"{http://www.tei-c.org/ns/1.0}ref\":\n",
    "            for token in child.findall(\"./{http://www.tei-c.org/ns/1.0}w\"):\n",
    "                count += 1\n",
    "                nb = token.get('n')\n",
    "                texte = get_w_text(token)\n",
    "                pdict[count] = {'nb':nb, 'text':texte}\n",
    "                \n",
    "        elif child.tag == \"{http://www.tei-c.org/ns/1.0}add\":\n",
    "            for token in child.findall(\"./{http://www.tei-c.org/ns/1.0}w\"):\n",
    "                count += 1\n",
    "                nb = token.get('n')\n",
    "                texte = get_w_text(token)\n",
    "                pdict[count] = {'nb':nb, 'text':texte}\n",
    "    \n",
    "    return pdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105d7f4",
   "metadata": {},
   "source": [
    "## FUNCTION: Compile a token dict into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "407622af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_str(tokendict):\n",
    "    \n",
    "    divlist = []\n",
    "    \n",
    "    for ind in sorted(tokendict.keys()):\n",
    "        \n",
    "        wtxt = tokendict[ind]['text']\n",
    "        \n",
    "        # If the list is empty, add the current word to the list.\n",
    "        if len(divlist) == 0:\n",
    "            divlist.append(wtxt)\n",
    "\n",
    "        # If the token is a punctuation character which\n",
    "        # is not separated from the previous word by a space,\n",
    "        # add it to the last entry in the list.\n",
    "        elif wtxt in noLspace:\n",
    "            divlist[-1] += wtxt\n",
    "\n",
    "        # If the last entry in the list is a character which\n",
    "        # is not separated from the next word by a space,\n",
    "        # add the current token to it.\n",
    "        elif divlist[-1] in noRspace:\n",
    "                divlist[-1] += wtxt\n",
    "\n",
    "        # If the last letter in the last entry in the list is\n",
    "        # a character which is not separated from the next word\n",
    "        # by a space, add the current token to it.\n",
    "        elif divlist[-1][-1] in noRspace:\n",
    "            divlist[-1] += wtxt\n",
    "        \n",
    "        #elif wtxt in insecable:\n",
    "        #    divlist[-1] += \"\\u00a0\"\n",
    "        #    divlist[-1] += wtxt\n",
    "\n",
    "        # Otherwise, just add the token as a new list entry.\n",
    "        else:\n",
    "            divlist.append(wtxt)\n",
    "\n",
    "        # Once you have treated every token in the title, make the\n",
    "        # return string by adding a space between each list entry.\n",
    "    stringed = \" \".join(divlist)\n",
    "    \n",
    "    return stringed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed108f",
   "metadata": {},
   "source": [
    "## FUNCTION: Construct the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206c1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(parag, refnbs):\n",
    "    \n",
    "    # parag = ET.Element(\"p\")\n",
    "    # before = list (liste de valeurs d'@n)\n",
    "    \n",
    "    after = False\n",
    "    \n",
    "    befdict = {}\n",
    "    refdict = {}\n",
    "    afdict = {}\n",
    "    left = \"\"\n",
    "    mention = \"\"\n",
    "    right = \"\"\n",
    "    \n",
    "    for worder in parag.keys():\n",
    "        count = worder\n",
    "        wnb = parag[worder]['nb']\n",
    "        wtxt = parag[worder]['text']\n",
    "        \n",
    "        if after == True:\n",
    "            afdict[worder] = parag[worder]\n",
    "        \n",
    "        else:\n",
    "            if wnb in refnbs:\n",
    "                refdict[worder] = parag[worder]\n",
    "                if wnb == refnbs[-1]:\n",
    "                    after = True\n",
    "            else:\n",
    "                befdict[worder] = parag[worder]\n",
    "    \n",
    "    left = dict_to_str(befdict)\n",
    "    right = dict_to_str(afdict)\n",
    "    mention = dict_to_str(refdict)\n",
    "    \n",
    "    returndict = {'left':left, 'mention':mention, 'right':right}\n",
    "    \n",
    "    return returndict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f0237",
   "metadata": {},
   "source": [
    "## FUNCTION: Concordancer for ONE author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c51e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordances(authorid, bookpath):\n",
    "    \n",
    "    refstr = \"#\" + authorid\n",
    "    \n",
    "    partcount = 0\n",
    "    chptcount = 0\n",
    "    sctcount = 0\n",
    "    frontcount = 0\n",
    "    refcount= 0\n",
    "    \n",
    "    authordict = {}\n",
    "        \n",
    "    with open(bookpath) as xmlfile:\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for part in root.findall('.//{http://www.tei-c.org/ns/1.0}div[@type=\"part\"]'):\n",
    "            partcount += 1\n",
    "            partitle = title_str(part, \"part\", partcount)\n",
    "\n",
    "            for chapter in part.findall('.//{http://www.tei-c.org/ns/1.0}div[@type=\"chapter\"]'):\n",
    "                chptcount += 1\n",
    "                chaptitle = title_str(chapter, \"chapter\", chptcount)\n",
    "                \n",
    "                for section in chapter.findall('.//{http://www.tei-c.org/ns/1.0}div[@type=\"section\"]'):\n",
    "                    sctcount += 1\n",
    "                    \n",
    "                    sectitle = title_str(section, \"section\", sctcount)\n",
    "                        \n",
    "                    for interesting in section.findall(\".//{http://www.tei-c.org/ns/1.0}p[{http://www.tei-c.org/ns/1.0}ref]\"):\n",
    "                        \n",
    "                        for ref in interesting.findall(\"./{http://www.tei-c.org/ns/1.0}ref\"):\n",
    "                            \n",
    "                            if ref.get('corresp') == refstr:\n",
    "                                \n",
    "                                whole_p = p_tokens(interesting)\n",
    "                                refcount += 1\n",
    "\n",
    "                                refnbs = []\n",
    "                                \n",
    "                                for refw in ref.findall('./{http://www.tei-c.org/ns/1.0}w'):\n",
    "                                    refnbs.append(refw.get('n'))\n",
    "                                \n",
    "                                sortedp = get_context(whole_p, refnbs)\n",
    "                                str_p = dict_to_str(whole_p)\n",
    "                                \n",
    "                                    \n",
    "                                authordict[refcount] = {\n",
    "                                    'ctxtg':sortedp['left'],\n",
    "                                    'mention':sortedp['mention'],\n",
    "                                    'ctxtd':sortedp['right'],\n",
    "                                    'p':str_p,\n",
    "                                    'part':partitle,\n",
    "                                    'chpt':chaptitle,\n",
    "                                    'sct':sectitle\n",
    "                                }\n",
    "    \n",
    "    return authordict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d48263",
   "metadata": {},
   "source": [
    "## Using the previously declared functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV columns:\n",
    "columns = [\"ID\",\"Auteur\", \"N°\", \"Témoin\", \"Contexte G\", \"Mention\", \"Contexte D\", \"Paragraphe\", \"Partie\", \"Chapitre\", \"Section\"]\n",
    "\n",
    "for author in authors.keys():\n",
    "    authorname = authors[author]['name']\n",
    "    authorpath = new_dir + \"/\" + author + \".csv\"\n",
    "    csv_output = []\n",
    "    \n",
    "    for witness in witnesses:\n",
    "        fullpath = binpath + witness + einpath\n",
    "        bookdict = concordances(author, fullpath)\n",
    "            \n",
    "        for occurrence in bookdict.keys():\n",
    "            occ = bookdict[occurrence]\n",
    "            csv_line = {\n",
    "                \"ID\":author,\n",
    "                \"Auteur\":authorname,\n",
    "                \"N°\":occurrence,\n",
    "                \"Témoin\":witness,\n",
    "                \"Contexte G\":occ['ctxtg'],\n",
    "                \"Mention\":occ['mention'],\n",
    "                \"Contexte D\":occ['ctxtd'],\n",
    "                \"Paragraphe\":occ['p'],\n",
    "                \"Partie\":occ['part'],\n",
    "                \"Chapitre\":occ['chpt'],\n",
    "                \"Section\":occ['sct']\n",
    "                \n",
    "            }\n",
    "            csv_output.append(csv_line)\n",
    "\n",
    "\n",
    "    with open(authorpath, 'w') as csvtobe:\n",
    "        csvwriting = csv.DictWriter(csvtobe, fieldnames=columns)\n",
    "        csvwriting.writeheader()\n",
    "        csvwriting.writerows(csv_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
