{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69482303",
   "metadata": {},
   "source": [
    "# Extraction and classification of classical references from the ConDÉ corpus\n",
    "\n",
    "Script written by Morgane Pica for a submission to the symposium [\"Lire les classiques en Normandie\"](https://rmblf.be/2022/02/04/appel-a-contribution-lire-les-classiques-en-normandie/) (oct 2022), to be written by herself and Mathieu Goux.\n",
    "\n",
    "This script contains several functions, in this exact order in the file:\n",
    "* `extract(witness, path)` -> Function taking the identifier of a TEI-XML file and the general path containing the TEI-XML corpus in need of analysis. Each new author declaration will be added to a general dictionary external to the function.\n",
    "* `get_w_text(word)` -> Function taking a `<tei:w>` element and returning its compiled textual content.\n",
    "* `title_str(div, div_type, div_count)` -> Function taking a `<tei:div>` element with lemmatized text and returning its title, if any.\n",
    "* `p_tokens(paragraph)` -> Function taking a `<tei:p>` element and returning all its words as a dictionary.\n",
    "* `dict_to_str(token_dict)` -> Function taking a dictionary as produced by `p_tokens()` and returning the corresponding string.\n",
    "* `get_context(paragraph, ref_numbers)` -> Function taking a dictionary as produced by `p_tokens()` and the list of the numbers of the tokens of a particular `<tei:ref>` element inside that paragraph, and sorting the tokens between left context, relevant text and right context.\n",
    "* `concordances(author_id, book_path)` -> Function taking the identifier of an author and the path to a TEI-XML file, and using the previous functions to gather relevant information on all mentions of this author in this file. It returns a dictionary for this author.\n",
    "\n",
    "## Imports & declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b04c0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm #tqdm est bibliothèque qui permet d'avoir une barre de progression\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "ET.register_namespace(\"\", \"http://www.tei-c.org/ns/1.0\")\n",
    "ET.register_namespace('xml','http://www.w3.org/XML/1998/namespace')\n",
    "\n",
    "# Get current time\n",
    "dt = datetime.now()\n",
    "tmsp = dt.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Not all witnesses were enriched with reference identification.\n",
    "# Change paths to fit your own folder organization.\n",
    "witnesses = [\"basnage\",\"berault\",\"merville\",\"pesnelle\",\"terrien\"]\n",
    "binpath = \"/home/mpica/Progs/perso/CONDE/editions/base-version/\"\n",
    "einpath = \"_base.xml\"\n",
    "\n",
    "\n",
    "# Construct the path for outputs. \n",
    "current_dir = os.getcwd()\n",
    "new_dir = f\"{current_dir}/output/extraction_{tmsp}\"\n",
    "os.mkdir(new_dir)\n",
    "\n",
    "# Change output paths here if you like.\n",
    "# Make CSV path now.\n",
    "idrefd_csv = f'{new_dir}/idref_authors_{tmsp}.csv'\n",
    "idrefd_json = f'{new_dir}/idref_authors_{tmsp}.json'\n",
    "classic_idrefd = f'{new_dir}/idref_classics_{tmsp}.csv'\n",
    "all_classic_occurrences = f'{new_dir}/all_classic_occurrences_{tmsp}.csv'\n",
    "\n",
    "# Lists of characters to be treated particularly.\n",
    "noLspace = \",.)/]-'\"\n",
    "noRspace = \"(/[]-'\"\n",
    "# insecable = \";:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e1c1f",
   "metadata": {},
   "source": [
    "### FUNCTION: Prepare dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbfb605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateprep(first, second, third, fourth):\n",
    "    if first == \"none\" or first == None or first == \"\":\n",
    "        first == \"0000\"\n",
    "    if second == \"none\" or second == None or second == \"\":\n",
    "        second == \"0000\"\n",
    "    if third == \"none\" or third == None or third == \"\":\n",
    "        third = str(\"{:04}\".format(int(first) + 100))\n",
    "    if fourth == \"none\" or fourth == None or fourth == \"\":\n",
    "        fourth = str(\"{:04}\".format(int(second) + 100))\n",
    "    return first + \"-01-01\", second + \"-01-01\", third + \"-01-01\", fourth + \"-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fac8e",
   "metadata": {},
   "source": [
    "## FUNCTION: extract authors and store in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f7c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = {}\n",
    "\n",
    "def extract(witness, path):\n",
    "    print(\"Extracting authors on -> \"+ witness)\n",
    "    \n",
    "    \"\"\"\n",
    "    Function taking the name and path to a TEI-XML text file and\n",
    "    analyzing the references, doing two things:\n",
    "        - returning an XML element named after the current witness,\n",
    "            itself containing the copy of each reference declaration,\n",
    "        - completing the general author dictionnary with new elements,\n",
    "            whether new authors or authors whose informations were\n",
    "            incomplete.\n",
    "            \n",
    "    :param witness: Name (=id) of the current witness as str (no space)\n",
    "    :param path: Path to the current witness TEI-XML file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the witness element.\n",
    "    liste = ET.Element(witness)\n",
    "    \n",
    "    # Open and parse TEI-XML file.\n",
    "    with open(path) as filein:\n",
    "        tree = ET.parse(filein)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Look for all declared authors.\n",
    "        for author in tqdm(root.findall('.//{http://www.tei-c.org/ns/1.0}listPerson/{http://www.tei-c.org/ns/1.0}person')):\n",
    "            \n",
    "            # Get <birth> element.\n",
    "            fullbirth = author.find('.//{http://www.tei-c.org/ns/1.0}birth')\n",
    "            fulldeath = author.find('.//{http://www.tei-c.org/ns/1.0}death')\n",
    "            \n",
    "            try:\n",
    "                author.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "            except:\n",
    "                print(\"Weird guy here, not finding their ID.\")\n",
    "                \n",
    "            try:\n",
    "                # Get current author identifier.\n",
    "                ident = author.get(\"{http://www.w3.org/XML/1998/namespace}id\")\n",
    "                \n",
    "                if ident not in authors.keys():\n",
    "                    \n",
    "                    try:\n",
    "                        bnf = author.get('sameAs')\n",
    "                    except:\n",
    "                        bnf = \"None\"\n",
    "                    \n",
    "                    # Create a dict. entry for the current author.\n",
    "                    authors[ident] = {}\n",
    "                    authors[ident][\"bnf\"] = bnf\n",
    "                                \n",
    "                    try:\n",
    "                        # Get current author birth date.\n",
    "                        \n",
    "                        if \"when\" in fullbirth.attrib.keys():\n",
    "                            authors[ident][\"earliest-birth\"] = fullbirth.get(\"when\")\n",
    "                            authors[ident][\"latest-birth\"] = fullbirth.get(\"when\")\n",
    "                        else:\n",
    "                            authors[ident][\"earliest-birth\"] = fullbirth.get(\"notBefore\")\n",
    "                            authors[ident][\"latest-birth\"] = fullbirth.get(\"notAfter\")\n",
    "                            \n",
    "                    except:\n",
    "                        authors[ident][\"earliest-birth\"] = \"none\"\n",
    "                        authors[ident][\"latest-birth\"] = \"none\"\n",
    "                        liste.append(author)\n",
    "                    \n",
    "                    try:\n",
    "                        # Get current author death date.\n",
    "                        \n",
    "                        if \"when\" in fullbirth.attrib.keys():\n",
    "                            authors[ident][\"earliest-death\"] = fulldeath.get(\"when\")\n",
    "                            authors[ident][\"latest-death\"] = fulldeath.get(\"when\")\n",
    "                        else:\n",
    "                            authors[ident][\"earliest-death\"] = fulldeath.get(\"notBefore\")\n",
    "                            authors[ident][\"latest-death\"] = fulldeath.get(\"notAfter\")\n",
    "                            \n",
    "                    except:\n",
    "                        authors[ident][\"earliest-death\"] = \"none\"\n",
    "                        authors[ident][\"latest-death\"] = \"none\"\n",
    "                        liste.append(author)\n",
    "                        \n",
    "\n",
    "                    try:\n",
    "                        # Create a dict. to store all recorded names for current author.\n",
    "                        lg = {}\n",
    "                        \n",
    "                        # Loop on names, store their language.\n",
    "                        for name in author.findall('.//{http://www.tei-c.org/ns/1.0}persName'):\n",
    "                            namelang = name.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n",
    "                            \n",
    "                            if name.text:\n",
    "                                # If name is not split into <forename>/<surname> elements,\n",
    "                                # there is text directly into <persName> element and we\n",
    "                                # make this the current language text.\n",
    "                                lg[namelang] = name.text\n",
    "                                \n",
    "                            else:\n",
    "                                # If name is split, the order is unsure, therefore\n",
    "                                # we store each kind into its own entry\n",
    "                                # within names dict. and make a final str out of it.\n",
    "                                names = {}\n",
    "                                for nchild in name.findall('*'):\n",
    "                                    if nchild.tag == \"{http://www.tei-c.org/ns/1.0}forename\":\n",
    "                                        names[\"fn\"] = nchild.text\n",
    "                                    elif nchild.tag == \"{http://www.tei-c.org/ns/1.0}surname\":\n",
    "                                        names[\"sn\"] = nchild.text\n",
    "                                    \n",
    "                                lg[namelang] = names[\"fn\"] + \" \" + names[\"sn\"]\n",
    "                                \n",
    "                        \n",
    "                        # Setting an order of preference for final display of name:\n",
    "                        # preferably French, if not, Latin, and if neither, English.\n",
    "                        # (These are the only three name languages within the corpus.)\n",
    "                        if \"fr\" in lg.keys():\n",
    "                            authors[ident][\"name\"] = lg[\"fr\"]\n",
    "                        elif \"la\" in lg.keys():\n",
    "                            authors[ident][\"name\"] = lg[\"la\"]\n",
    "                        elif \"eng\" in lg.keys():\n",
    "                            authors[ident][\"name\"] = lg[\"eng\"]\n",
    "                            \n",
    "                    except:\n",
    "                        authors[ident][\"name\"] = \"none\"\n",
    "                        liste.append(author)\n",
    "                    \n",
    "                # If the author was recorded in a previous witness but has no name,\n",
    "                # we try to make a name string again with this witness.\n",
    "                \n",
    "                elif authors[ident][\"name\"] == \"none\":\n",
    "                    \n",
    "                    try:\n",
    "                        lg = {}\n",
    "                        for name in author.findall('.//{http://www.tei-c.org/ns/1.0}persName'):\n",
    "                            namelang = name.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n",
    "                            if name.text:\n",
    "                                lg[namelang] = name.text\n",
    "                                \n",
    "                            else:\n",
    "                                names = {}\n",
    "                                for nchild in name.findall('*'):\n",
    "                                    if nchild.tag == \"{http://www.tei-c.org/ns/1.0}forename\":\n",
    "                                        names[\"fn\"] = nchild.text\n",
    "                                    elif nchild.tag == \"{http://www.tei-c.org/ns/1.0}surname\":\n",
    "                                        names[\"sn\"] = nchild.text\n",
    "                                        \n",
    "                                lg[namelang] = names[\"sn\"] + \", \" + names[\"fn\"]\n",
    "                                                            \n",
    "                        if \"fr\" in lg.keys():\n",
    "                            authors[ident][\"name\"] = lg[\"fr\"]\n",
    "                        elif \"la\" in lg.keys():\n",
    "                            authors[ident][\"name\"] = lg[\"la\"]\n",
    "                        elif \"eng\" in lg.keys():\n",
    "                            authors[ident][\"name\"] = lg[\"eng\"]\n",
    "                            \n",
    "                    except:\n",
    "                        authors[ident][\"name\"] = \"none\"\n",
    "                        liste.append(author)\n",
    "                \n",
    "                else:\n",
    "                    print(f\"{ident} is already in the dict, so I'm not making it.\")\n",
    "                \n",
    "            except:\n",
    "                print(\"I'm extracting authors for the first time. There is a problem with one.\")\n",
    "                continue\n",
    "    \n",
    "    return liste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15451f81",
   "metadata": {},
   "source": [
    "## FUNCTION: extract text from tei:w element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dacc1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_text(word):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function taking a <tei:w> element and\n",
    "    returning its compiled textual content.\n",
    "    \n",
    "    :param word: ET.Element('{http://www.tei-c.org/ns/1.0}w')\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Preparing the return string as an empty string.\n",
    "    texte = \"\"\n",
    "    \n",
    "    # If there is text directly inside <w> element and\n",
    "    # before the first child, add it.\n",
    "    if word.text:\n",
    "        texte += str(word.text)\n",
    "                \n",
    "    # Loop on all current <w> children.\n",
    "    for item in word:\n",
    "            \n",
    "        # If current child is <tei:height> or <tei:supplied>\n",
    "        if item.tag == '{http://www.tei-c.org/ns/1.0}height' or item.tag == '{http://www.tei-c.org/ns/1.0}supplied':\n",
    "            # Add text.\n",
    "            texte += str(item.text)\n",
    "            # If any, add the text following current child.\n",
    "            if item.tail:\n",
    "                texte += str(item.tail)\n",
    "                \n",
    "        # If current child is <tei:lb>, add the following text.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}lb':\n",
    "            if item.tail:\n",
    "                texte += str(item.tail)\n",
    "                        \n",
    "        # If current child is <tei:choice>, add the second child of <choice>\n",
    "        # (<tei:reg> or <tei:expan>), then add the text following current child if any.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}choice':\n",
    "            texte += str(item[1].text)\n",
    "            if item.tail:\n",
    "                texte += str(item.tail)\n",
    "        \n",
    "        # If current child is <tei:c>, add its text, then the following text if any.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}c':\n",
    "            texte += item.text\n",
    "            if item.tail:\n",
    "                texte += str(item.tail)\n",
    "        \n",
    "        \n",
    "        # If current child is <tei:hi>, add its text, then the following text if any.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}hi':\n",
    "            texte += item.text\n",
    "            if item.tail:\n",
    "                texte += item.tail\n",
    "        \n",
    "        # If current child is <tei:add>, loop on its children and do the same checks.\n",
    "        elif item.tag == '{http://www.tei-c.org/ns/1.0}add':\n",
    "            # On refait tous les tests.\n",
    "            if item.find('.') == None :\n",
    "                texte = str(item.text)\n",
    "                            \n",
    "            else:\n",
    "                        \n",
    "                if item.text:\n",
    "                    texte += str(item.text)\n",
    "                        \n",
    "                for subitem in item:\n",
    "                    if subitem.tag == '{http://www.tei-c.org/ns/1.0}lb':\n",
    "                        if subitem.tail:\n",
    "                            texte += str(subitem.tail)\n",
    "                    elif subitem.tag == '{http://www.tei-c.org/ns/1.0}choice':\n",
    "                        texte += str(subitem[1].text)\n",
    "                        if subitem.tail:\n",
    "                            texte += str(subitem.tail)\n",
    "                            \n",
    "    return texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88816f4",
   "metadata": {},
   "source": [
    "## FUNCTION: Make title string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df8c2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_str(div):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function taking a <tei:div> element with lemmatized text\n",
    "    and returning its title, if any.\n",
    "    \n",
    "    :param div: ET.Element('{http://www.tei-c.org/ns/1.0}div')\n",
    "    :param dcount: integer\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Lists of characters to be treated particularly.\n",
    "    noLspace = \",.)/]-'\"\n",
    "    noRspace = \"(/[]-'\"\n",
    "    # insecable = \";:\"\n",
    "    \n",
    "    # List of strings to be filled.\n",
    "    divlist = []\n",
    "    \n",
    "    try:\n",
    "        # If you do find a title as first child of div, make its text.\n",
    "        if div.find('./*[1]').tag == \"{http://www.tei-c.org/ns/1.0}head\":\n",
    "            \n",
    "            # Loop on each <tei:w> word token.\n",
    "            for word in div.findall('./{http://www.tei-c.org/ns/1.0}head/{http://www.tei-c.org/ns/1.0}w'):\n",
    "                \n",
    "                # Compile the text of current <tei:w> element.\n",
    "                wtxt = get_w_text(word)\n",
    "                \n",
    "                # If the list is empty, add the current word to the list.\n",
    "                if len(divlist) == 0:\n",
    "                    divlist.append(wtxt)\n",
    "\n",
    "                # If the token is a punctuation character which\n",
    "                # is not separated from the previous word by a space,\n",
    "                # add it to the last entry in the list.\n",
    "                elif wtxt in noLspace:\n",
    "                    divlist[-1] += wtxt\n",
    "                \n",
    "                # If the last entry in the list is a character which\n",
    "                # is not separated from the next word by a space,\n",
    "                # add the current token to it.\n",
    "                elif divlist[-1] in noRspace:\n",
    "                    divlist[-1] += wtxt\n",
    "\n",
    "                # If the last letter in the last entry in the list is\n",
    "                # a character which is not separated from the next word\n",
    "                # by a space, add the current token to it.\n",
    "                elif divlist[-1][-1] in noRspace:\n",
    "                    divlist[-1] += wtxt\n",
    "\n",
    "                #elif wtxt in insecable:\n",
    "                #    divlist[-1] += \"\\u00a0\"\n",
    "                #    divlist[-1] += wtxt\n",
    "                \n",
    "                # Otherwise, just add the token as a new list entry.\n",
    "                else:\n",
    "                    divlist.append(wtxt)\n",
    "            \n",
    "            # Once you have treated every token in the title, make the\n",
    "            # return string by adding a space between each list entry.\n",
    "            title = \" \".join(divlist)\n",
    "        \n",
    "        # If there is no title to the div but it has an @subtype,\n",
    "        # its value makes the return string.\n",
    "        elif div.get('subtype') != None:\n",
    "            title = div.get('subtype')\n",
    "            \n",
    "        elif div.get('type') not in ['part','chapter','section']:\n",
    "            title = div.get('type')\n",
    "        \n",
    "        else:\n",
    "            title = \"Aucun titre.\"\n",
    "    \n",
    "    # Just a marker to spot errors within final output.\n",
    "    except Exception as e:\n",
    "        print(e, \"-> Could not construct string for: \"+ ET.tostring(word).decode('utf-8') + \" in \" + div.get('{http://www.w3.org/XML/1998/namespace}id'))\n",
    "        title = \"Pas réussi.\"\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a96e1",
   "metadata": {},
   "source": [
    "## FUNCTION: Make a dictionary from the tokens in a paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0b0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_tokens(parag):\n",
    "    \n",
    "    pdict = {}\n",
    "    count = 0\n",
    "    \n",
    "    for child in parag.findall(\"./*\"):\n",
    "        \n",
    "        if child.tag == \"{http://www.tei-c.org/ns/1.0}w\":\n",
    "            count += 1\n",
    "            nb = child.get('n')\n",
    "            texte = get_w_text(child)\n",
    "            pdict[count] = {'nb':nb, 'text':texte}\n",
    "            \n",
    "            \n",
    "        elif child.tag == \"{http://www.tei-c.org/ns/1.0}ref\":\n",
    "            for token in child.findall(\"./{http://www.tei-c.org/ns/1.0}w\"):\n",
    "                count += 1\n",
    "                nb = token.get('n')\n",
    "                texte = get_w_text(token)\n",
    "                pdict[count] = {'nb':nb, 'text':texte}\n",
    "                \n",
    "        elif child.tag == \"{http://www.tei-c.org/ns/1.0}add\":\n",
    "            for token in child.findall(\"./{http://www.tei-c.org/ns/1.0}w\"):\n",
    "                count += 1\n",
    "                nb = token.get('n')\n",
    "                texte = get_w_text(token)\n",
    "                pdict[count] = {'nb':nb, 'text':texte}\n",
    "    \n",
    "    return pdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7d75e",
   "metadata": {},
   "source": [
    "## FUNCTION: Compile a token dict into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c4b7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_str(tokendict):\n",
    "    \n",
    "    divlist = []\n",
    "    \n",
    "    for ind in sorted(tokendict.keys()):\n",
    "        \n",
    "        wtxt = tokendict[ind]['text']\n",
    "        \n",
    "        # If the list is empty, add the current word to the list.\n",
    "        if len(divlist) == 0:\n",
    "            divlist.append(wtxt)\n",
    "\n",
    "        # If the token is a punctuation character which\n",
    "        # is not separated from the previous word by a space,\n",
    "        # add it to the last entry in the list.\n",
    "        elif wtxt in noLspace:\n",
    "            divlist[-1] += wtxt\n",
    "\n",
    "        # If the last entry in the list is a character which\n",
    "        # is not separated from the next word by a space,\n",
    "        # add the current token to it.\n",
    "        elif divlist[-1] in noRspace:\n",
    "                divlist[-1] += wtxt\n",
    "\n",
    "        # If the last letter in the last entry in the list is\n",
    "        # a character which is not separated from the next word\n",
    "        # by a space, add the current token to it.\n",
    "        elif divlist[-1][-1] in noRspace:\n",
    "            divlist[-1] += wtxt\n",
    "        \n",
    "        #elif wtxt in insecable:\n",
    "        #    divlist[-1] += \"\\u00a0\"\n",
    "        #    divlist[-1] += wtxt\n",
    "\n",
    "        # Otherwise, just add the token as a new list entry.\n",
    "        else:\n",
    "            divlist.append(wtxt)\n",
    "\n",
    "        # Once you have treated every token in the title, make the\n",
    "        # return string by adding a space between each list entry.\n",
    "    stringed = \" \".join(divlist)\n",
    "    \n",
    "    return stringed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe0358",
   "metadata": {},
   "source": [
    "## FUNCTION: Construct the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc33ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(parag, refnbs):\n",
    "    \n",
    "    # parag = ET.Element(\"p\")\n",
    "    # before = list (liste de valeurs d'@n)\n",
    "    \n",
    "    after = False\n",
    "    \n",
    "    befdict = {}\n",
    "    refdict = {}\n",
    "    afdict = {}\n",
    "    left = \"\"\n",
    "    mention = \"\"\n",
    "    right = \"\"\n",
    "    \n",
    "    for worder in parag.keys():\n",
    "        count = worder\n",
    "        wnb = parag[worder]['nb']\n",
    "        wtxt = parag[worder]['text']\n",
    "        \n",
    "        if after == True:\n",
    "            afdict[worder] = parag[worder]\n",
    "        \n",
    "        else:\n",
    "            if wnb in refnbs:\n",
    "                refdict[worder] = parag[worder]\n",
    "                if wnb == refnbs[-1]:\n",
    "                    after = True\n",
    "            else:\n",
    "                befdict[worder] = parag[worder]\n",
    "    \n",
    "    left = dict_to_str(befdict)\n",
    "    right = dict_to_str(afdict)\n",
    "    mention = dict_to_str(refdict)\n",
    "    \n",
    "    returndict = {'left':left, 'mention':mention, 'right':right}\n",
    "    \n",
    "    return returndict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99991ed2",
   "metadata": {},
   "source": [
    "## FUNCTION: Concordancer for ONE author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4d6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordances(authorid, bookpath):\n",
    "    \n",
    "    refstr = \"#\" + authorid\n",
    "    \n",
    "    partcount = 0\n",
    "    chptcount = 0\n",
    "    sctcount = 0\n",
    "    frontcount = 0\n",
    "    refcount= 0\n",
    "    \n",
    "    authordict = {}\n",
    "        \n",
    "    with open(bookpath) as xmlfile:\n",
    "        tree = ET.parse(xmlfile)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for frontdiv in root.findall('.//{http://www.tei-c.org/ns/1.0}front/{http://www.tei-c.org/ns/1.0}div'):\n",
    "            partcount += 1\n",
    "            divtype = frontdiv.get('type')\n",
    "            partitle = title_str(frontdiv)\n",
    "\n",
    "            for interesting in frontdiv.findall(\".//{http://www.tei-c.org/ns/1.0}p[{http://www.tei-c.org/ns/1.0}ref]\"):\n",
    "                        \n",
    "                for ref in interesting.findall(\"./{http://www.tei-c.org/ns/1.0}ref\"):\n",
    "                            \n",
    "                    if ref.get('corresp') == refstr:\n",
    "                                \n",
    "                        whole_p = p_tokens(interesting)\n",
    "                        refcount += 1\n",
    "                        refnbs = []\n",
    "                                \n",
    "                        for refw in ref.findall('./{http://www.tei-c.org/ns/1.0}w'):\n",
    "                            refnbs.append(refw.get('n'))\n",
    "                                \n",
    "                        sortedp = get_context(whole_p, refnbs)\n",
    "                        str_p = dict_to_str(whole_p)\n",
    "                                \n",
    "                                    \n",
    "                        authordict[refcount] = {\n",
    "                            'ctxtg':sortedp['left'],\n",
    "                            'mention':sortedp['mention'],\n",
    "                            'ctxtd':sortedp['right'],\n",
    "                            'p':str_p,\n",
    "                            'part':\"<front>\",\n",
    "                            'chpt':partitle,\n",
    "                            'sct':\"\"\n",
    "                        }\n",
    "        \n",
    "        for part in root.findall('.//{http://www.tei-c.org/ns/1.0}div[@type=\"part\"]'):\n",
    "            partcount += 1\n",
    "            partitle = title_str(part)\n",
    "\n",
    "            for chapter in part.findall('.//{http://www.tei-c.org/ns/1.0}div[@type=\"chapter\"]'):\n",
    "                chptcount += 1\n",
    "                chaptitle = title_str(chapter)\n",
    "                \n",
    "                for section in chapter.findall('.//{http://www.tei-c.org/ns/1.0}div[@type=\"section\"]'):\n",
    "                    sctcount += 1\n",
    "                    \n",
    "                    sectitle = title_str(section)\n",
    "                        \n",
    "                    for interesting in section.findall(\".//{http://www.tei-c.org/ns/1.0}p[{http://www.tei-c.org/ns/1.0}ref]\"):\n",
    "                        \n",
    "                        for ref in interesting.findall(\"./{http://www.tei-c.org/ns/1.0}ref\"):\n",
    "                            \n",
    "                            if ref.get('corresp') == refstr:\n",
    "                                \n",
    "                                whole_p = p_tokens(interesting)\n",
    "                                refcount += 1\n",
    "\n",
    "                                refnbs = []\n",
    "                                \n",
    "                                for refw in ref.findall('./{http://www.tei-c.org/ns/1.0}w'):\n",
    "                                    refnbs.append(refw.get('n'))\n",
    "                                \n",
    "                                sortedp = get_context(whole_p, refnbs)\n",
    "                                str_p = dict_to_str(whole_p)\n",
    "                                \n",
    "                                    \n",
    "                                authordict[refcount] = {\n",
    "                                    'ctxtg':sortedp['left'],\n",
    "                                    'mention':sortedp['mention'],\n",
    "                                    'ctxtd':sortedp['right'],\n",
    "                                    'p':str_p,\n",
    "                                    'part':partitle,\n",
    "                                    'chpt':chaptitle,\n",
    "                                    'sct':sectitle\n",
    "                                }\n",
    "    \n",
    "    return authordict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e2af3",
   "metadata": {},
   "source": [
    "## Getting the author list with information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9b9dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting authors on -> basnage\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692af662110845f897397012582af398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting authors on -> berault\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b3e21a7f2045a49918583048a1218c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ulpien is already in the dict, so I'm not making it.\n",
      "cassiod is already in the dict, so I'm not making it.\n",
      "aulus is already in the dict, so I'm not making it.\n",
      "solon is already in the dict, so I'm not making it.\n",
      "papon is already in the dict, so I'm not making it.\n",
      "cicero is already in the dict, so I'm not making it.\n",
      "plutarque is already in the dict, so I'm not making it.\n",
      "verro is already in the dict, so I'm not making it.\n",
      "bartole is already in the dict, so I'm not making it.\n",
      "tite-live is already in the dict, so I'm not making it.\n",
      "platon is already in the dict, so I'm not making it.\n",
      "charondas is already in the dict, so I'm not making it.\n",
      "bouteiller is already in the dict, so I'm not making it.\n",
      "guenois is already in the dict, so I'm not making it.\n",
      "afflito is already in the dict, so I'm not making it.\n",
      "rebuffe is already in the dict, so I'm not making it.\n",
      "alciat is already in the dict, so I'm not making it.\n",
      "bohier is already in the dict, so I'm not making it.\n",
      "aufreri is already in the dict, so I'm not making it.\n",
      "tacite is already in the dict, so I'm not making it.\n",
      "bened is already in the dict, so I'm not making it.\n",
      "du-moulin is already in the dict, so I'm not making it.\n",
      "papae is already in the dict, so I'm not making it.\n",
      "bourdin is already in the dict, so I'm not making it.\n",
      "coquille is already in the dict, so I'm not making it.\n",
      "alex-3 is already in the dict, so I'm not making it.\n",
      "imbert is already in the dict, so I'm not making it.\n",
      "chenu is already in the dict, so I'm not making it.\n",
      "masuer is already in the dict, so I'm not making it.\n",
      "maynard is already in the dict, so I'm not making it.\n",
      "faber-joannes is already in the dict, so I'm not making it.\n",
      "decius is already in the dict, so I'm not making it.\n",
      "cujas is already in the dict, so I'm not making it.\n",
      "terrien is already in the dict, so I'm not making it.\n",
      "chass is already in the dict, so I'm not making it.\n",
      "bacq is already in the dict, so I'm not making it.\n",
      "bald is already in the dict, so I'm not making it.\n",
      "chopin is already in the dict, so I'm not making it.\n",
      "homere is already in the dict, so I'm not making it.\n",
      "servius is already in the dict, so I'm not making it.\n",
      "panorme is already in the dict, so I'm not making it.\n",
      "bodin is already in the dict, so I'm not making it.\n",
      "louet is already in the dict, so I'm not making it.\n",
      "covar is already in the dict, so I'm not making it.\n",
      "lampride is already in the dict, so I'm not making it.\n",
      "suetone is already in the dict, so I'm not making it.\n",
      "pithou is already in the dict, so I'm not making it.\n",
      "ammian is already in the dict, so I'm not making it.\n",
      "quintilien is already in the dict, so I'm not making it.\n",
      "arg is already in the dict, so I'm not making it.\n",
      "justinien is already in the dict, so I'm not making it.\n",
      "bud is already in the dict, so I'm not making it.\n",
      "arist is already in the dict, so I'm not making it.\n",
      "saluste is already in the dict, so I'm not making it.\n",
      "halic is already in the dict, so I'm not making it.\n",
      "greg-1 is already in the dict, so I'm not making it.\n",
      "hostiensis is already in the dict, so I'm not making it.\n",
      "andreas is already in the dict, so I'm not making it.\n",
      "s-cyprien is already in the dict, so I'm not making it.\n",
      "bonif is already in the dict, so I'm not making it.\n",
      "seneca is already in the dict, so I'm not making it.\n",
      "goveanus is already in the dict, so I'm not making it.\n",
      "plaute is already in the dict, so I'm not making it.\n",
      "terence is already in the dict, so I'm not making it.\n",
      "castre is already in the dict, so I'm not making it.\n",
      "cittadini is already in the dict, so I'm not making it.\n",
      "corte is already in the dict, so I'm not making it.\n",
      "peleus is already in the dict, so I'm not making it.\n",
      "pline is already in the dict, so I'm not making it.\n",
      "lommeau is already in the dict, so I'm not making it.\n",
      "hotman is already in the dict, so I'm not making it.\n",
      "orto is already in the dict, so I'm not making it.\n",
      "le-maistre is already in the dict, so I'm not making it.\n",
      "clement-3 is already in the dict, so I'm not making it.\n",
      "livius is already in the dict, so I'm not making it.\n",
      "celse is already in the dict, so I'm not making it.\n",
      "labeon is already in the dict, so I'm not making it.\n",
      "tiraqueau is already in the dict, so I'm not making it.\n",
      "coras is already in the dict, so I'm not making it.\n",
      "virgile is already in the dict, so I'm not making it.\n",
      "poly-vir is already in the dict, so I'm not making it.\n",
      "loyseau is already in the dict, so I'm not making it.\n",
      "du-luc is already in the dict, so I'm not making it.\n",
      "andegav is already in the dict, so I'm not making it.\n",
      "sainson is already in the dict, so I'm not making it.\n",
      "galli is already in the dict, so I'm not making it.\n",
      "augustin is already in the dict, so I'm not making it.\n",
      "herodote is already in the dict, so I'm not making it.\n",
      "zasius is already in the dict, so I'm not making it.\n",
      "greg-tours is already in the dict, so I'm not making it.\n",
      "corradus is already in the dict, so I'm not making it.\n",
      "trebatius is already in the dict, so I'm not making it.\n",
      "smith is already in the dict, so I'm not making it.\n",
      "s-paul is already in the dict, so I'm not making it.\n",
      "caesar is already in the dict, so I'm not making it.\n",
      "ambroise is already in the dict, so I'm not making it.\n",
      "zacharie is already in the dict, so I'm not making it.\n",
      "inno-3 is already in the dict, so I'm not making it.\n",
      "s-jerome is already in the dict, so I'm not making it.\n",
      "isidore is already in the dict, so I'm not making it.\n",
      "s-luc is already in the dict, so I'm not making it.\n",
      "caton is already in the dict, so I'm not making it.\n",
      "duaren is already in the dict, so I'm not making it.\n",
      "leon is already in the dict, so I'm not making it.\n",
      "papinien is already in the dict, so I'm not making it.\n",
      "ragueau is already in the dict, so I'm not making it.\n",
      "oldendorpius is already in the dict, so I'm not making it.\n",
      "s-matthieu is already in the dict, so I'm not making it.\n",
      "gratien is already in the dict, so I'm not making it.\n",
      "const is already in the dict, so I'm not making it.\n",
      "jason is already in the dict, so I'm not making it.\n",
      "honorius is already in the dict, so I'm not making it.\n",
      "du-val is already in the dict, so I'm not making it.\n",
      "grimauder is already in the dict, so I'm not making it.\n",
      "greg-tolo is already in the dict, so I'm not making it.\n",
      "ferron is already in the dict, so I'm not making it.\n",
      "anast is already in the dict, so I'm not making it.\n",
      "accurse is already in the dict, so I'm not making it.\n",
      "apulee is already in the dict, so I'm not making it.\n",
      "Extracting authors on -> merville\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efc076d17444c79a2388e0b61142249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le-rouille is already in the dict, so I'm not making it.\n",
      "davir is already in the dict, so I'm not making it.\n",
      "terrien is already in the dict, so I'm not making it.\n",
      "godefroy is already in the dict, so I'm not making it.\n",
      "berault is already in the dict, so I'm not making it.\n",
      "littleton is already in the dict, so I'm not making it.\n",
      "dudo is already in the dict, so I'm not making it.\n",
      "chopin is already in the dict, so I'm not making it.\n",
      "du-moulin is already in the dict, so I'm not making it.\n",
      "justinien is already in the dict, so I'm not making it.\n",
      "cujas is already in the dict, so I'm not making it.\n",
      "rheginon is already in the dict, so I'm not making it.\n",
      "aimoin is already in the dict, so I'm not making it.\n",
      "coquille is already in the dict, so I'm not making it.\n",
      "beaumanoir is already in the dict, so I'm not making it.\n",
      "scaliger is already in the dict, so I'm not making it.\n",
      "ragueau is already in the dict, so I'm not making it.\n",
      "seneca is already in the dict, so I'm not making it.\n",
      "tiraqueau is already in the dict, so I'm not making it.\n",
      "papae is already in the dict, so I'm not making it.\n",
      "bignon is already in the dict, so I'm not making it.\n",
      "du-fresne is already in the dict, so I'm not making it.\n",
      "bald is already in the dict, so I'm not making it.\n",
      "arg is already in the dict, so I'm not making it.\n",
      "bacq is already in the dict, so I'm not making it.\n",
      "const is already in the dict, so I'm not making it.\n",
      "ricard is already in the dict, so I'm not making it.\n",
      "rebuffe is already in the dict, so I'm not making it.\n",
      "ferron is already in the dict, so I'm not making it.\n",
      "spelman is already in the dict, so I'm not making it.\n",
      "matt-paris is already in the dict, so I'm not making it.\n",
      "Extracting authors on -> pesnelle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759dd47d74c442589a665078a0656ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matt-paris is already in the dict, so I'm not making it.\n",
      "du-chesne is already in the dict, so I'm not making it.\n",
      "spelman is already in the dict, so I'm not making it.\n",
      "vossius is already in the dict, so I'm not making it.\n",
      "menage is already in the dict, so I'm not making it.\n",
      "ragueau is already in the dict, so I'm not making it.\n",
      "du-cange is already in the dict, so I'm not making it.\n",
      "glanville is already in the dict, so I'm not making it.\n",
      "breton is already in the dict, so I'm not making it.\n",
      "littleton is already in the dict, so I'm not making it.\n",
      "bracton is already in the dict, so I'm not making it.\n",
      "stanford is already in the dict, so I'm not making it.\n",
      "selden is already in the dict, so I'm not making it.\n",
      "couvellus is already in the dict, so I'm not making it.\n",
      "afflito is already in the dict, so I'm not making it.\n",
      "skenaeus is already in the dict, so I'm not making it.\n",
      "tacite is already in the dict, so I'm not making it.\n",
      "marculphe is already in the dict, so I'm not making it.\n",
      "bignon is already in the dict, so I'm not making it.\n",
      "greg-tours is already in the dict, so I'm not making it.\n",
      "lindem is already in the dict, so I'm not making it.\n",
      "sirmond is already in the dict, so I'm not making it.\n",
      "beaumanoir is already in the dict, so I'm not making it.\n",
      "brodeau is already in the dict, so I'm not making it.\n",
      "bouteiller is already in the dict, so I'm not making it.\n",
      "du-moulin is already in the dict, so I'm not making it.\n",
      "le-rouille is already in the dict, so I'm not making it.\n",
      "terrien is already in the dict, so I'm not making it.\n",
      "basnage is already in the dict, so I'm not making it.\n",
      "godefroy is already in the dict, so I'm not making it.\n",
      "berault is already in the dict, so I'm not making it.\n",
      "loyseau is already in the dict, so I'm not making it.\n",
      "louet is already in the dict, so I'm not making it.\n",
      "loysel is already in the dict, so I'm not making it.\n",
      "fevret is already in the dict, so I'm not making it.\n",
      "cujas is already in the dict, so I'm not making it.\n",
      "du-pineau is already in the dict, so I'm not making it.\n",
      "coquille is already in the dict, so I'm not making it.\n",
      "arg is already in the dict, so I'm not making it.\n",
      "bacq is already in the dict, so I'm not making it.\n",
      "bardet is already in the dict, so I'm not making it.\n",
      "le-prestre is already in the dict, so I'm not making it.\n",
      "la-lande is already in the dict, so I'm not making it.\n",
      "mornac is already in the dict, so I'm not making it.\n",
      "chopin is already in the dict, so I'm not making it.\n",
      "le-bret is already in the dict, so I'm not making it.\n",
      "papon is already in the dict, so I'm not making it.\n",
      "salvaing is already in the dict, so I'm not making it.\n",
      "roche-flavin is already in the dict, so I'm not making it.\n",
      "ricard is already in the dict, so I'm not making it.\n",
      "chass is already in the dict, so I'm not making it.\n",
      "bourdin is already in the dict, so I'm not making it.\n",
      "boniface is already in the dict, so I'm not making it.\n",
      "fontaines is already in the dict, so I'm not making it.\n",
      "galli is already in the dict, so I'm not making it.\n",
      "monstrelet is already in the dict, so I'm not making it.\n",
      "bartole is already in the dict, so I'm not making it.\n",
      "justinien is already in the dict, so I'm not making it.\n",
      "alex-3 is already in the dict, so I'm not making it.\n",
      "tillet is already in the dict, so I'm not making it.\n",
      "fabri is already in the dict, so I'm not making it.\n",
      "auzanet is already in the dict, so I'm not making it.\n",
      "fortin is already in the dict, so I'm not making it.\n",
      "charondas is already in the dict, so I'm not making it.\n",
      "bald is already in the dict, so I'm not making it.\n",
      "zasius is already in the dict, so I'm not making it.\n",
      "pithou is already in the dict, so I'm not making it.\n",
      "cazeneuve is already in the dict, so I'm not making it.\n",
      "dominici is already in the dict, so I'm not making it.\n",
      "papae is already in the dict, so I'm not making it.\n",
      "bodin is already in the dict, so I'm not making it.\n",
      "clement-3 is already in the dict, so I'm not making it.\n",
      "sainson is already in the dict, so I'm not making it.\n",
      "pontanus is already in the dict, so I'm not making it.\n",
      "lommeau is already in the dict, so I'm not making it.\n",
      "troncon is already in the dict, so I'm not making it.\n",
      "tournet is already in the dict, so I'm not making it.\n",
      "greg-1 is already in the dict, so I'm not making it.\n",
      "davir is already in the dict, so I'm not making it.\n",
      "cambol is already in the dict, so I'm not making it.\n",
      "le-maistre is already in the dict, so I'm not making it.\n",
      "de-roye is already in the dict, so I'm not making it.\n",
      "marechal is already in the dict, so I'm not making it.\n",
      "bened is already in the dict, so I'm not making it.\n",
      "rainutius is already in the dict, so I'm not making it.\n",
      "theveneau is already in the dict, so I'm not making it.\n",
      "buridan is already in the dict, so I'm not making it.\n",
      "rebuffe is already in the dict, so I'm not making it.\n",
      "inno-3 is already in the dict, so I'm not making it.\n",
      "tiraqueau is already in the dict, so I'm not making it.\n",
      "la-roque is already in the dict, so I'm not making it.\n",
      "montholon is already in the dict, so I'm not making it.\n",
      "grimauder is already in the dict, so I'm not making it.\n",
      "vigier is already in the dict, so I'm not making it.\n",
      "cassiod is already in the dict, so I'm not making it.\n",
      "thesaurus is already in the dict, so I'm not making it.\n",
      "smith is already in the dict, so I'm not making it.\n",
      "buchanan is already in the dict, so I'm not making it.\n",
      "decius is already in the dict, so I'm not making it.\n",
      "aufreri is already in the dict, so I'm not making it.\n",
      "ulpien is already in the dict, so I'm not making it.\n",
      "bereng is already in the dict, so I'm not making it.\n",
      "bouguier is already in the dict, so I'm not making it.\n",
      "olive is already in the dict, so I'm not making it.\n",
      "robert is already in the dict, so I'm not making it.\n",
      "const is already in the dict, so I'm not making it.\n",
      "plutarque is already in the dict, so I'm not making it.\n",
      "virgile is already in the dict, so I'm not making it.\n",
      "expil is already in the dict, so I'm not making it.\n",
      "sauvageau is already in the dict, so I'm not making it.\n",
      "s-paul is already in the dict, so I'm not making it.\n",
      "duaren is already in the dict, so I'm not making it.\n",
      "maynard is already in the dict, so I'm not making it.\n",
      "grotius is already in the dict, so I'm not making it.\n",
      "poly-vir is already in the dict, so I'm not making it.\n",
      "paulus is already in the dict, so I'm not making it.\n",
      "calixte-3 is already in the dict, so I'm not making it.\n",
      "seneca is already in the dict, so I'm not making it.\n",
      "caesar is already in the dict, so I'm not making it.\n",
      "cicero is already in the dict, so I'm not making it.\n",
      "papinien is already in the dict, so I'm not making it.\n",
      "Extracting authors on -> terrien\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd4d87a5e9b45d78752745c610edc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aristote is already in the dict, so I'm not making it.\n",
      "gratien is already in the dict, so I'm not making it.\n",
      "s-paul is already in the dict, so I'm not making it.\n",
      "severe is already in the dict, so I'm not making it.\n",
      "le-rouille is already in the dict, so I'm not making it.\n",
      "cicero is already in the dict, so I'm not making it.\n",
      "augustin is already in the dict, so I'm not making it.\n",
      "justinien is already in the dict, so I'm not making it.\n",
      "paulus is already in the dict, so I'm not making it.\n",
      "ulpien is already in the dict, so I'm not making it.\n",
      "pline is already in the dict, so I'm not making it.\n",
      "virgile is already in the dict, so I'm not making it.\n",
      "plutarque is already in the dict, so I'm not making it.\n",
      "quintilien is already in the dict, so I'm not making it.\n",
      "bald is already in the dict, so I'm not making it.\n",
      "rebuffe is already in the dict, so I'm not making it.\n",
      "bud is already in the dict, so I'm not making it.\n",
      "tiraqueau is already in the dict, so I'm not making it.\n",
      "imbert is already in the dict, so I'm not making it.\n",
      "papon is already in the dict, so I'm not making it.\n",
      "chartier is already in the dict, so I'm not making it.\n",
      "aufreri is already in the dict, so I'm not making it.\n",
      "bened is already in the dict, so I'm not making it.\n",
      "rainutius is already in the dict, so I'm not making it.\n",
      "s-jerome is already in the dict, so I'm not making it.\n",
      "masuer is already in the dict, so I'm not making it.\n",
      "bohier is already in the dict, so I'm not making it.\n",
      "papae is already in the dict, so I'm not making it.\n",
      "bartole is already in the dict, so I'm not making it.\n",
      "chass is already in the dict, so I'm not making it.\n",
      "aemyl is already in the dict, so I'm not making it.\n",
      "caesar is already in the dict, so I'm not making it.\n",
      "pierre-blois is already in the dict, so I'm not making it.\n",
      "platon is already in the dict, so I'm not making it.\n",
      "accurse is already in the dict, so I'm not making it.\n",
      "faber-joannes is already in the dict, so I'm not making it.\n",
      "thesaurus is already in the dict, so I'm not making it.\n",
      "celse is already in the dict, so I'm not making it.\n",
      "ambroise is already in the dict, so I'm not making it.\n",
      "du-moulin is already in the dict, so I'm not making it.\n",
      "zasius is already in the dict, so I'm not making it.\n",
      "tacite is already in the dict, so I'm not making it.\n",
      "boece is already in the dict, so I'm not making it.\n",
      "poly-vir is already in the dict, so I'm not making it.\n",
      "tertullien is already in the dict, so I'm not making it.\n",
      "hotman is already in the dict, so I'm not making it.\n",
      "galli is already in the dict, so I'm not making it.\n",
      "martin-5 is already in the dict, so I'm not making it.\n",
      "calixte-3 is already in the dict, so I'm not making it.\n",
      "alex-3 is already in the dict, so I'm not making it.\n",
      "inno-3 is already in the dict, so I'm not making it.\n",
      "bonif is already in the dict, so I'm not making it.\n",
      "clement-5 is already in the dict, so I'm not making it.\n",
      "horace is already in the dict, so I'm not making it.\n",
      "corte is already in the dict, so I'm not making it.\n",
      "diocletien is already in the dict, so I'm not making it.\n",
      "maximien is already in the dict, so I'm not making it.\n",
      "castre is already in the dict, so I'm not making it.\n",
      "panorme is already in the dict, so I'm not making it.\n",
      "martial is already in the dict, so I'm not making it.\n",
      "angel is already in the dict, so I'm not making it.\n",
      "balduin is already in the dict, so I'm not making it.\n",
      "du-luc is already in the dict, so I'm not making it.\n",
      "plaute is already in the dict, so I'm not making it.\n",
      "aulus is already in the dict, so I'm not making it.\n",
      "solon is already in the dict, so I'm not making it.\n",
      "neratius is already in the dict, so I'm not making it.\n",
      "homere is already in the dict, so I'm not making it.\n",
      "crantsius is already in the dict, so I'm not making it.\n",
      "servius is already in the dict, so I'm not making it.\n",
      "alciat is already in the dict, so I'm not making it.\n",
      "suetone is already in the dict, so I'm not making it.\n",
      "seneca is already in the dict, so I'm not making it.\n",
      "xenophon is already in the dict, so I'm not making it.\n",
      "strabo is already in the dict, so I'm not making it.\n",
      "adrien is already in the dict, so I'm not making it.\n",
      "andreas is already in the dict, so I'm not making it.\n",
      "labeon is already in the dict, so I'm not making it.\n",
      "pausanias is already in the dict, so I'm not making it.\n",
      "bourdin is already in the dict, so I'm not making it.\n",
      "dominici is already in the dict, so I'm not making it.\n",
      "marcellus is already in the dict, so I'm not making it.\n"
     ]
    }
   ],
   "source": [
    "# Initiate the root element for the XML debugging file.\n",
    "listroot = ET.Element(\"people\")\n",
    "\n",
    "# Loop on witnesses: construct the path from initial vars,\n",
    "# then trigger extract() function on current witness,\n",
    "# so as to both make the according element for the XML debugging file,\n",
    "# and fill the general author dictionary.\n",
    "\n",
    "for witness in witnesses:\n",
    "    fullpath = binpath + witness + einpath\n",
    "    \n",
    "    listroot.append(extract(witness, fullpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cf8d0",
   "metadata": {},
   "source": [
    "## Query IdRef on authors and make general lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0940e15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023547206347467a9bc9125791566c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_output = []\n",
    "info_output = []\n",
    "\n",
    "for author in tqdm(authors.keys()):\n",
    "    try:\n",
    "        link = authors[author][\"bnf\"]\n",
    "        bnf=link.replace(\"catalogue\", \"data\").replace(\"https\",\"http\")\n",
    "\n",
    "        querystart = \"\"\"\n",
    "            PREFIX foaf: <http://xmlns.com/foaf/0.1/> \n",
    "            PREFIX dcterms: <http://purl.org/dc/terms/> \n",
    "            PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "            PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "\n",
    "            SELECT ?prefLabel ?personne\n",
    "            WHERE {\n",
    "              ?personne a foaf:Person ;\n",
    "                        owl:sameAs <\"\"\"\n",
    "\n",
    "        queryend = \"\"\"#foaf:Person> ;\n",
    "                        skos:prefLabel ?prefLabel .\n",
    "            }\"\"\"\n",
    "\n",
    "        fullquery = querystart + bnf + queryend\n",
    "\n",
    "        # Specify the DBPedia endpoint\n",
    "        sparql = SPARQLWrapper(\"https://data.idref.fr/sparql\")\n",
    "\n",
    "        # Query for the description of \"Capsaicin\", filtered by language\n",
    "        sparql.setQuery(fullquery)\n",
    "\n",
    "        # Convert results to JSON format\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        result = sparql.query().convert()\n",
    "        output = result[\"results\"][\"bindings\"][0]\n",
    "\n",
    "        try:\n",
    "            current = {\n",
    "                \"id\":author,\n",
    "                \"ConDÉ name\":authors[author][\"name\"],\n",
    "                \"found\":\"yes\",\n",
    "                \"IdRef name\":output[\"prefLabel\"][\"value\"],\n",
    "                \"BnF\":bnf,\n",
    "                \"IdRef\":output[\"personne\"][\"value\"],\n",
    "                \"earliest birth\":authors[author][\"earliest-birth\"],\n",
    "                \"latest birth\":authors[author][\"latest-birth\"],\n",
    "                \"earliest death\":authors[author][\"earliest-death\"],\n",
    "                \"latest death\":authors[author][\"latest-death\"]\n",
    "            }\n",
    "            csv_output.append(current)\n",
    "            \n",
    "        except:\n",
    "            current = {\n",
    "                \"id\":author,\n",
    "                \"ConDÉ name\":authors[author][\"name\"],\n",
    "                \"found\":\"yes\",\n",
    "                \"IdRef name\":\"\",\n",
    "                \"BnF\":bnf,\n",
    "                \"IdRef\":\"\",\n",
    "                \"earliest birth\":authors[author][\"earliest-birth\"],\n",
    "                \"latest birth\":authors[author][\"latest-birth\"],\n",
    "                \"earliest death\":authors[author][\"earliest-death\"],\n",
    "                \"latest death\":authors[author][\"latest-death\"]\n",
    "            }\n",
    "            csv_output.append(current)\n",
    "            \n",
    "    except:\n",
    "        current = {\n",
    "                \"id\":author,\n",
    "                \"ConDÉ name\":authors[author][\"name\"],\n",
    "                \"found\":\"no\",\n",
    "                \"IdRef name\":\"\",\n",
    "                \"BnF\":\"\",\n",
    "                \"IdRef\":\"\",\n",
    "                \"earliest birth\":authors[author][\"earliest-birth\"],\n",
    "                \"latest birth\":authors[author][\"latest-birth\"],\n",
    "                \"earliest death\":authors[author][\"earliest-death\"],\n",
    "                \"latest death\":authors[author][\"latest-death\"]\n",
    "            }\n",
    "        csv_output.append(current)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a9e37",
   "metadata": {},
   "source": [
    "## Make the basic author files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e59ef61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0706126d1bf54798821e1b88a9211f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anian\n",
      "herold\n",
      "arq\n",
      "goncanus\n",
      "febur\n",
      "s-michel\n",
      "masurier\n",
      "chartier\n",
      "ald\n",
      "frigentius\n",
      "fillesac\n",
      "adrien-pape\n",
      "s-matthieu\n",
      "fortin\n",
      "adrien\n",
      "moise\n",
      "froben\n",
      "s-thomas\n",
      "josephe\n",
      "balduin\n",
      "s-jeanbap\n",
      "josue\n",
      "bannes\n",
      "evariste\n",
      "montholon\n",
      "bonneton\n",
      "bam\n",
      "colombel\n",
      "pape-lucius\n",
      "marcellus\n",
      "s-luc\n",
      "angel\n",
      "nicephore\n",
      "muncer\n",
      "iudaus\n",
      "anchar\n",
      "timarchus\n",
      "skinner\n",
      "lauriere\n",
      "perard\n",
      "robertson\n",
      "gillet\n",
      "camus\n",
      "rigord\n",
      "nicod\n",
      "duplessis\n",
      "chantreau\n",
      "gousset\n",
      "vedel\n",
      "morgues\n",
      "everard\n",
      "renauldon\n",
      "bertheaume\n",
      "maillard\n",
      "gouget\n",
      "avezan\n"
     ]
    }
   ],
   "source": [
    "with open(idrefd_csv,\"w\") as csvfile:\n",
    "    csvwriting = csv.DictWriter(csvfile, fieldnames = [\"id\", \"ConDÉ name\", \"found\", \"IdRef name\", \"BnF\", \"IdRef\", \"earliest birth\", \"latest birth\",\"earliest death\", \"latest death\"])\n",
    "    csvwriting.writeheader()\n",
    "    csvwriting.writerows(csv_output)\n",
    "    \n",
    "with open(idrefd_json, \"w\") as jsonfile:\n",
    "    json.dump(csv_output, jsonfile, ensure_ascii=False)\n",
    "\n",
    "for author in tqdm(csv_output):\n",
    "    try:\n",
    "        if int(author[\"earliest birth\"]) <= 560:\n",
    "            info_output.append(author)\n",
    "    except:\n",
    "        print(author[\"id\"])\n",
    "            \n",
    "with open(classic_idrefd, \"w\") as authorfile:\n",
    "    csvwriting = csv.DictWriter(authorfile, fieldnames = [\"id\", \"ConDÉ name\", \"found\", \"IdRef name\", \"BnF\", \"IdRef\", \"earliest birth\", \"latest birth\",\"earliest death\", \"latest death\"])\n",
    "    csvwriting.writeheader()\n",
    "    csvwriting.writerows(info_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3202f6",
   "metadata": {},
   "source": [
    "## Get mentions of all relevant authors and output one table each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f05ae7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfd029753e248e4a094cbdd3a772a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CSV columns:\n",
    "columns_l = [\"ID\",\"Auteur\", \"BnF\", \"IdRef\", \"Naissance (min)\", \"Naissance (max)\", \"Mort (min)\", \"Mort (max)\", \"N°\", \"Témoin\", \"Contexte G\", \"Mention\", \"Contexte D\", \"Paragraphe\", \"Partie\", \"Chapitre\", \"Section\"]\n",
    "all_occs = []\n",
    "occstr = \"\"\n",
    "all_authors_one_file = []\n",
    "\n",
    "for author in tqdm(info_output):\n",
    "    authorname = author['IdRef name']\n",
    "    authorpath = new_dir + \"/\" + author['id'] + \".csv\"\n",
    "    author_output = []\n",
    "    birthmin, birthmax, deathmin, deathmax = dateprep(author[\"earliest birth\"], author[\"latest birth\"], author[\"earliest death\"], author[\"latest death\"])\n",
    "    \n",
    "    for witness in witnesses:\n",
    "        fullpath = binpath + witness + einpath\n",
    "        bookdict = concordances(author['id'], fullpath)\n",
    "            \n",
    "        for occurrence in bookdict.keys():\n",
    "            occ = bookdict[occurrence]\n",
    "            csv_line = {\n",
    "                \"ID\":author['id'],\n",
    "                \"Auteur\":author['IdRef name'],\n",
    "                \"BnF\":author['BnF'],\n",
    "                \"IdRef\":author['IdRef'],\n",
    "                \"Naissance (min)\":birthmin,\n",
    "                \"Naissance (max)\":birthmax,\n",
    "                \"Mort (min)\":deathmin,\n",
    "                \"Mort (max)\":deathmax,\n",
    "                \"N°\":occurrence,\n",
    "                \"Témoin\":witness,\n",
    "                \"Contexte G\":occ['ctxtg'],\n",
    "                \"Mention\":occ['mention'],\n",
    "                \"Contexte D\":occ['ctxtd'],\n",
    "                \"Paragraphe\":occ['p'],\n",
    "                \"Partie\":occ['part'],\n",
    "                \"Chapitre\":occ['chpt'],\n",
    "                \"Section\":occ['sct']\n",
    "                \n",
    "            }\n",
    "            author_output.append(csv_line)\n",
    "            all_authors_one_file.append(csv_line)\n",
    "            \n",
    "    countoccs = str(len(author_output))\n",
    "    \n",
    "    all_occs.append({'id':author['id'], 'nb': countoccs})\n",
    "    \n",
    "    with open(authorpath, 'w') as csvtobe:\n",
    "        csvwriting = csv.DictWriter(csvtobe, fieldnames=columns_l)\n",
    "        csvwriting.writeheader()\n",
    "        csvwriting.writerows(author_output)\n",
    "        \n",
    "for author in all_occs:\n",
    "    occstr += f\"{author['id']} was spotted {author['nb']} times.\\n\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e62ceb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_dir + \"/rapport.txt\", \"w\") as txtfile:\n",
    "    txtfile.write(occstr)\n",
    "    \n",
    "with open(all_classic_occurrences, \"w\") as csvfile:\n",
    "    csvwriting = csv.DictWriter(csvfile, fieldnames=columns_l)\n",
    "    csvwriting.writeheader()\n",
    "    csvwriting.writerows(all_authors_one_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
